{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c969ec03",
   "metadata": {},
   "source": [
    "First, I have to download and preprocess the dataset. CIFAR-10 is a well-known image classification dataset that contains 60,000 32x32 color images in 10 classes, with 6,000 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d16fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Download and preprocess the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape((50000, -1))\n",
    "x_test = x_test.reshape((10000, -1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d6428",
   "metadata": {},
   "source": [
    "Next, we can perform k-fold cross-validation to estimate the performance of the k-NN models with different distance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3842e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross-validation with Manhattan distance matrix on the CIFAR-10 dataset\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=5, p=1)\n",
    "cv_scores_manhattan = cross_val_score(knn_manhattan, x_train, np.argmax(y_train, axis=1), cv=5)\n",
    "\n",
    "# Perform k-fold cross-validation with Euclidean distance matrix on the CIFAR-10 dataset\n",
    "knn_euclidean = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "cv_scores_euclidean = cross_val_score(knn_euclidean, x_train, np.argmax(y_train, axis=1), cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f3e70",
   "metadata": {},
   "source": [
    "After cross-validation, we can compute the mean and standard deviation of the cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fd997d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Manhattan distance matrix): [0.3737 0.3612 0.3695 0.3581 0.3575]\n",
      "Mean cross-validation score (Manhattan distance matrix): 0.364\n",
      "Standard deviation of the cross-validation scores (Manhattan distance matrix): 0.006469003014375552\n",
      "Cross-validation scores (Euclidean distance matrix): [0.3326 0.3286 0.337  0.3317 0.3304]\n",
      "Mean cross-validation score (Euclidean distance matrix): 0.33205999999999997\n",
      "Standard deviation of the cross-validation scores (Euclidean distance matrix): 0.0028125433329995154\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and standard deviation of the cross-validation scores\n",
    "print('Cross-validation scores (Manhattan distance matrix):', cv_scores_manhattan)\n",
    "print('Mean cross-validation score (Manhattan distance matrix):', np.mean(cv_scores_manhattan))\n",
    "print('Standard deviation of the cross-validation scores (Manhattan distance matrix):', np.std(cv_scores_manhattan))\n",
    "print('Cross-validation scores (Euclidean distance matrix):', cv_scores_euclidean)\n",
    "print('Mean cross-validation score (Euclidean distance matrix):', np.mean(cv_scores_euclidean))\n",
    "print('Standard deviation of the cross-validation scores (Euclidean distance matrix):', np.std(cv_scores_euclidean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9eac62",
   "metadata": {},
   "source": [
    "Finally, we can plot the cross-validation scores and cross-accuracy of the k-NN models as a function of the number of neighbors. It also includes the values of k for the best cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the cross-validation scores and cross-accuracy of the k-NN models as a function of the number of neighbors\n",
    "cv_scores_manhattan = []\n",
    "cv_scores_euclidean = []\n",
    "accuracies_manhattan = []\n",
    "accuracies_euclidean = []\n",
    "for k in range(1, 11):\n",
    "    knn_manhattan = KNeighborsClassifier(n_neighbors=k, p=1)\n",
    "    knn_euclidean = KNeighborsClassifier(n_neighbors=k, p=2)\n",
    "    try:\n",
    "        cv_score_manhattan = np.mean(cross_val_score(knn_manhattan, x_train, np.argmax(y_train, axis=1), cv=5))\n",
    "    except:\n",
    "        cv_score_manhattan = 0\n",
    "    try:\n",
    "        cv_score_euclidean = np.mean(cross_val_score(knn_euclidean, x_train, np.argmax(y_train, axis=1), cv=5))\n",
    "    except:\n",
    "        cv_score_euclidean = 0\n",
    "    cv_scores_manhattan.append(cv_score_manhattan)\n",
    "    cv_scores_euclidean.append(cv_score_euclidean)\n",
    "    knn_manhattan.fit(x_train, np.argmax(y_train, axis=1))\n",
    "    knn_euclidean.fit(x_train, np.argmax(y_train, axis=1))\n",
    "    y_pred_manhattan = knn_manhattan.predict(x_test)\n",
    "    y_pred_euclidean = knn_euclidean.predict(x_test)\n",
    "    accuracy_manhattan = np.mean(np.argmax(y_test, axis=1) == y_pred_manhattan)\n",
    "    accuracy_euclidean = np.mean(np.argmax(y_test, axis=1) == y_pred_euclidean)\n",
    "    accuracies_manhattan.append(accuracy_manhattan)\n",
    "    accuracies_euclidean.append(accuracy_euclidean)\n",
    "\n",
    "best_k_manhattan = np.argmax(cv_scores_manhattan) + 1\n",
    "best_k_euclidean = np.argmax(cv_scores_euclidean) + 1\n",
    "\n",
    "plt.plot(range(1, 11), cv_scores_manhattan, label='Cross-validation (Manhattan distance matrix)')\n",
    "plt.plot(range(1, 11), cv_scores_euclidean, label='Cross-validation (Euclidean distance matrix)')\n",
    "plt.plot(range(1, 11), accuracies_manhattan, label='Cross-accuracy (Manhattan distance matrix)')\n",
    "plt.plot(range(1, 11), accuracies_euclidean, label='Cross-accuracy (Euclidean distance matrix)')\n",
    "plt.title('Performance of k-NN on CIFAR-10 dataset')\n",
    "plt.xlabel('Number of neighbors (k)')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best k for Manhattan distance matrix: {best_k_manhattan}\")\n",
    "print(f\"Best k for Euclidean distance matrix: {best_k_euclidean}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3335e",
   "metadata": {},
   "source": [
    "This code prints out the values of k that correspond to the best cross-validation scores for the Manhattan and Euclidean distance matrices. These values are obtained by finding the index of the maximum cross-validation score in the arrays cv_scores_manhattan and cv_scores_euclidean, and adding 1 to obtain the corresponding value of k."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
